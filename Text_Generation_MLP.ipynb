{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "72960e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "41addf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileHandler (fileName):\n",
    "    # load ascii text and covert to lowercase\n",
    "    raw_text = open(fileName, 'r', encoding='utf-8').read()\n",
    "    raw_text = raw_text.lower()\n",
    "    # create mapping of unique chars to integers\n",
    "    \n",
    "    uniqueChars = sorted(list(set(raw_text)))\n",
    "    vocabSize = len(uniqueChars)\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(uniqueChars))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(uniqueChars))\n",
    "    \n",
    "    integers = [char_to_int[char] for char in raw_text]\n",
    "    #We are doing One hot encoding as We want our MLP to work on it, and a classification problem\n",
    "    dataMatrix = np.eye(vocabSize)[integers]\n",
    "    return dataMatrix , vocabSize, char_to_int,int_to_char\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "447ede30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix , vocabSize, char_to_int,int_to_char = fileHandler(\"C:/Users/Lenovo/Desktop/My Git Repo/abcde.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2edb5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153594, 7) 7 \n",
      " {'\\n': 0, ' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6} \n",
      " {0: '\\n', 1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e'}\n"
     ]
    }
   ],
   "source": [
    "print(dataMatrix.shape,vocabSize,\"\\n\",char_to_int,\"\\n\",int_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb6f07",
   "metadata": {},
   "source": [
    "#### Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2293f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training input-output pairs\n",
    "X_train = dataMatrix[:-1]  # All rows except the last one\n",
    "Y_train = dataMatrix[1:]   # All rows except the first one\n",
    "\n",
    "inputs = torch.Tensor(X_train)\n",
    "#Take the max number (1 in our case) indice of the one hot enocding alongside column\n",
    "labels = torch.Tensor(np.argmax(Y_train, axis=1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5bf8cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "tensor([0., 0., 1., 0., 0., 0., 0.])\n",
      "{0: '\\n', 1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(int_to_char[2])\n",
    "print(inputs[0])\n",
    "print(int_to_char)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "545754e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "923dd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGeneratorMLP1(nn.Module):\n",
    "    def __init__(self,inputSize,outputSize):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.InputLayer = nn.Linear(in_features=inputSize,out_features=128)\n",
    "        self.HiddenLayer = nn.Linear(in_features=128,out_features=256)\n",
    "        self.HiddenLayer2 = nn.Linear(in_features=256,out_features=64)\n",
    "        self.OutputLayer = nn.Linear(in_features=64,out_features=outputSize)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.InputLayer(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.HiddenLayer(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.HiddenLayer2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.OutputLayer(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3e53b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = TextGeneratorMLP1(vocabSize,vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a404088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "416eb20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/1000], Loss: 0.1254\n",
      "Epoch [100/1000], Loss: 0.1080\n",
      "Epoch [150/1000], Loss: 0.1069\n",
      "Epoch [200/1000], Loss: 0.1066\n",
      "Epoch [250/1000], Loss: 0.1064\n",
      "Epoch [300/1000], Loss: 0.1063\n",
      "Epoch [350/1000], Loss: 0.1063\n",
      "Epoch [400/1000], Loss: 0.1062\n",
      "Epoch [450/1000], Loss: 0.1062\n",
      "Epoch [500/1000], Loss: 0.1062\n",
      "Epoch [550/1000], Loss: 0.1062\n",
      "Epoch [600/1000], Loss: 0.1062\n",
      "Epoch [650/1000], Loss: 0.1061\n",
      "Epoch [700/1000], Loss: 0.1061\n",
      "Epoch [750/1000], Loss: 0.1061\n",
      "Epoch [800/1000], Loss: 0.1061\n",
      "Epoch [850/1000], Loss: 0.1061\n",
      "Epoch [900/1000], Loss: 0.1061\n",
      "Epoch [950/1000], Loss: 0.1061\n",
      "Epoch [1000/1000], Loss: 0.1061\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    # here no need to use outputs.argmax as criterion CrossEntropyLoss do this and softmax on our behalf\n",
    "    loss = criterion(outputs, labels.long()) \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6b5e5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationFunction():\n",
    "    model.eval()\n",
    "    generatedString = \"\"\n",
    "    radomStartingPoint = np.random.randint(low=0,high=X_train.shape[0])\n",
    "    modelInput = inputs[radomStartingPoint]\n",
    "    print(radomStartingPoint,modelInput)\n",
    "    for i in range(50):\n",
    "        output = model(modelInput)\n",
    "        predicted_index = torch.argmax(output, dim=0).item()\n",
    "        char = int_to_char[predicted_index]\n",
    "        generatedString += char\n",
    "        modelInput = torch.Tensor(np.eye(vocabSize)[char_to_int[char]])\n",
    "    \n",
    "    print(generatedString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7ae20025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134962 tensor([0., 0., 0., 0., 0., 0., 1.])\n",
      " abcde abcde abcde abcde abcde abcde abcde abcde a\n"
     ]
    }
   ],
   "source": [
    "evaluationFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a98f48cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0, ' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1000a09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0, ' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1444ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "132904c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix , vocabSize, char_to_int,int_to_char = fileHandler(\"C:/Users/Lenovo/Desktop/My Git Repo/abcde_edcba.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c56e20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training input-output pairs\n",
    "X_train = np.concatenate((dataMatrix[:-2], dataMatrix[1:-1]), axis=1)  # Concatenate two consecutive one-hot-encoded vectors along columns\n",
    "Y_train = dataMatrix[2:]  # Next three one-hot-encoded vectors as output\n",
    "\n",
    "inputs = torch.Tensor(X_train)\n",
    "#Take the max number (1 in our case) indice of the one hot enocding alongside column\n",
    "labels = torch.Tensor(np.argmax(Y_train, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "75853944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0.] [0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(dataMatrix[0],dataMatrix[1],dataMatrix[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d9310dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0.] 4.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0],Y_train[0],labels[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fe65560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = TextGeneratorMLP1(vocabSize*2,vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0a0e7176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextGeneratorMLP1(\n",
      "  (InputLayer): Linear(in_features=14, out_features=128, bias=True)\n",
      "  (HiddenLayer): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (HiddenLayer2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (OutputLayer): Linear(in_features=64, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0fc77d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c5978cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/150], Loss: 0.1772\n",
      "Epoch [100/150], Loss: 0.0026\n",
      "Epoch [150/150], Loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    # here no need to use outputs.argmax as criterion CrossEntropyLoss do this and softmax on our behalf\n",
    "    loss = criterion(outputs, labels.long()) \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a27359bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationFunction():\n",
    "    model.eval()\n",
    "    generatedString = \"\"\n",
    "    radomStartingPoint = np.random.randint(low=0,high=X_train.shape[0])\n",
    "    modelInput = inputs[radomStartingPoint]\n",
    "    print(radomStartingPoint,modelInput)\n",
    "    for i in range(50):\n",
    "        #print(modelInput)\n",
    "        output = model(modelInput)\n",
    "        predicted_index = torch.argmax(output, dim=0).item()\n",
    "        char = int_to_char[predicted_index]\n",
    "        generatedString += char\n",
    "        newCharacterEncoding = torch.Tensor(np.eye(vocabSize)[char_to_int[char]])\n",
    "        modelInput = torch.cat((modelInput[-7:],newCharacterEncoding),dim=0)\n",
    "        #print(f\"NewEncoding:{newCharacterEncoding}, predicted_index:{predicted_index}, char:{char}, modelInput : {modelInput}\")\n",
    "    \n",
    "    print(generatedString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "96b1adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39243 tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      " edcba\n",
      "abcde edcba\n",
      "abcde edcba\n",
      "abcde edcba\n",
      "abcde e\n"
     ]
    }
   ],
   "source": [
    "evaluationFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63bbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
