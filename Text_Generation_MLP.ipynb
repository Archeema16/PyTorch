{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72960e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41addf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileHandler (fileName):\n",
    "    # load ascii text and covert to lowercase\n",
    "    raw_text = open(fileName, 'r', encoding='utf-8').read()\n",
    "    raw_text = raw_text.lower()\n",
    "    # create mapping of unique chars to integers\n",
    "    \n",
    "    uniqueChars = sorted(list(set(raw_text)))\n",
    "    vocabSize = len(uniqueChars)\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(uniqueChars))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(uniqueChars))\n",
    "    \n",
    "    integers = [char_to_int[char] for char in raw_text]\n",
    "    #We are doing One hot encoding as We want our MLP to work on it, and a classification problem\n",
    "    dataMatrix = np.eye(vocabSize)[integers]\n",
    "    return dataMatrix , vocabSize, char_to_int,int_to_char\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447ede30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix , vocabSize, char_to_int,int_to_char = fileHandler(\"C:/Users/Lenovo/Desktop/My Git Repo/abcde.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2edb5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153594, 7) 7 \n",
      " {'\\n': 0, ' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6} \n",
      " {0: '\\n', 1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e'}\n"
     ]
    }
   ],
   "source": [
    "print(dataMatrix.shape,vocabSize,\"\\n\",char_to_int,\"\\n\",int_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb6f07",
   "metadata": {},
   "source": [
    "#### Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2293f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training input-output pairs\n",
    "X_train = dataMatrix[:-1]  # All rows except the last one\n",
    "Y_train = dataMatrix[1:]   # All rows except the first one\n",
    "\n",
    "inputs = torch.Tensor(X_train)\n",
    "#Take the max number (1 in our case) indice of the one hot enocding alongside column\n",
    "labels = torch.Tensor(np.argmax(Y_train, axis=1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf8cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "tensor([0., 0., 1., 0., 0., 0., 0.])\n",
      "{0: '\\n', 1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(int_to_char[2])\n",
    "print(inputs[0])\n",
    "print(int_to_char)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923dd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGeneratorMLP(nn.Module):\n",
    "    def __init__(self,inputSize,outputSize):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.InputLayer = nn.Linear(in_features=inputSize,out_features=128)\n",
    "        self.HiddenLayer = nn.Linear(in_features=128,out_features=256)\n",
    "        self.HiddenLayer2 = nn.Linear(in_features=256,out_features=64)\n",
    "        self.OutputLayer = nn.Linear(in_features=64,out_features=outputSize)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.InputLayer(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.HiddenLayer(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.HiddenLayer2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.OutputLayer(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e53b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = TextGeneratorMLP(vocabSize,vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a404088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "416eb20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/200], Loss: 0.2218\n",
      "Epoch [100/200], Loss: 0.1097\n",
      "Epoch [150/200], Loss: 0.1078\n",
      "Epoch [200/200], Loss: 0.1070\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    # here no need to use outputs.argmax as criterion CrossEntropyLoss do this and softmax on our behalf\n",
    "    loss = criterion(outputs, labels.long()) \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b5e5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationFunction():\n",
    "    model.eval()\n",
    "    generatedString = \"\"\n",
    "    radomStartingPoint = np.random.randint(low=0,high=inputs.shape[0])\n",
    "    modelInput = inputs[radomStartingPoint]\n",
    "    startingInteger = torch.argmax(modelInput, dim=0).item()\n",
    "    startingCharacter = int_to_char[startingInteger]\n",
    "    #print(radomStartingPoint,modelInput)\n",
    "    for i in range(50):\n",
    "        output = model(modelInput)\n",
    "        predicted_index = torch.argmax(output, dim=0).item()\n",
    "        char = int_to_char[predicted_index]\n",
    "        generatedString += char\n",
    "        modelInput = torch.Tensor(np.eye(vocabSize)[char_to_int[char]])\n",
    "    \n",
    "    print(f\"Starting Character Randomly choosen in Integer: {startingInteger} in Alphabet: {startingCharacter}\")\n",
    "    print(\"Generated String:\", generatedString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ae20025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Character Randomly choosen in Integer: 3 in Alphabet: b\n",
      "Generated String: cde abcde abcde abcde abcde abcde abcde abcde abcd\n"
     ]
    }
   ],
   "source": [
    "evaluationFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1444ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "132904c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix , vocabSize, char_to_int,int_to_char = fileHandler(\"C:/Users/Lenovo/Desktop/My Git Repo/abcde_edcba.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c56e20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training input-output pairs\n",
    "X_train = np.concatenate((dataMatrix[:-2], dataMatrix[1:-1]), axis=1)  # Concatenate two consecutive one-hot-encoded vectors along columns\n",
    "Y_train = dataMatrix[2:]  # Next three one-hot-encoded vectors as output\n",
    "\n",
    "inputs = torch.Tensor(X_train)\n",
    "#Take the max number (1 in our case) indice of the one hot enocding alongside column\n",
    "labels = torch.Tensor(np.argmax(Y_train, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "75853944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0.] [0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(dataMatrix[0],dataMatrix[1],dataMatrix[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d9310dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0.] 4.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0],Y_train[0],labels[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe65560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = TextGeneratorMLP(vocabSize*2,vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a0e7176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextGeneratorMLP(\n",
      "  (InputLayer): Linear(in_features=14, out_features=128, bias=True)\n",
      "  (HiddenLayer): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (HiddenLayer2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (OutputLayer): Linear(in_features=64, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fc77d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5978cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/150], Loss: 0.0860\n",
      "Epoch [100/150], Loss: 0.0025\n",
      "Epoch [150/150], Loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    # here no need to use outputs.argmax as criterion CrossEntropyLoss do this and softmax on our behalf\n",
    "    loss = criterion(outputs, labels.long()) \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a27359bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationFunction():\n",
    "    model.eval()\n",
    "    generatedString = \"\"\n",
    "    radomStartingPoint = np.random.randint(low=0,high=inputs.shape[0])\n",
    "    modelInput = inputs[radomStartingPoint]\n",
    "    startingInteger1 = torch.argmax(modelInput[:7], dim=0).item()\n",
    "    startingInteger2 = torch.argmax(modelInput[7:], dim=0).item()\n",
    "    startingCharacter1 = int_to_char[startingInteger1]\n",
    "    startingCharacter2 = int_to_char[startingInteger2]\n",
    "    #print(radomStartingPoint,modelInput)\n",
    "    for i in range(50):\n",
    "        #print(modelInput)\n",
    "        output = model(modelInput)\n",
    "        predicted_index = torch.argmax(output, dim=0).item()\n",
    "        char = int_to_char[predicted_index]\n",
    "        generatedString += char\n",
    "        newCharacterEncoding = torch.Tensor(np.eye(vocabSize)[char_to_int[char]])\n",
    "        modelInput = torch.cat((modelInput[-7:],newCharacterEncoding),dim=0)\n",
    "\n",
    "    print(f\"Starting Characters Randomly choosen in Alphabets: {startingCharacter1,startingCharacter2}\")\n",
    "    print(\"Generated String:\", generatedString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96b1adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Characters Randomly choosen in Alphabets: ('d', 'e')\n",
      "Generated String:  edcba\n",
      "abcde edcba\n",
      "abcde edcba\n",
      "abcde edcba\n",
      "abcde e\n"
     ]
    }
   ],
   "source": [
    "evaluationFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee63bbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153598"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4993dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
