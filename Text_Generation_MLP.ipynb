{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72960e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileHandler (fileName):\n",
    "    # load ascii text and covert to lowercase\n",
    "    raw_text = open(fileName, 'r', encoding='utf-8').read()\n",
    "    raw_text = raw_text.lower()\n",
    "    # create mapping of unique chars to integers\n",
    "    \n",
    "    uniqueChars = sorted(list(set(raw_text)))\n",
    "    vocabSize = len(uniqueChars)\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(uniqueChars))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(uniqueChars))\n",
    "    \n",
    "    integers = [char_to_int[char] for char in raw_text]\n",
    "    #We are doing One hot encoding as We want our MLP to work on it, and a classification problem\n",
    "    dataMatrix = np.eye(vocabSize)[integers]\n",
    "    return dataMatrix , vocabSize, char_to_int,int_to_char\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36bcb53",
   "metadata": {},
   "source": [
    "### Text Generation with SIngle Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447ede30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix , vocabSize, char_to_int,int_to_char = fileHandler(\"C:/Users/Lenovo/Desktop/My Git Repo/abcde.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2edb5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153594, 7) 7 \n",
      " {'\\n': 0, ' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6} \n",
      " {0: '\\n', 1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e'}\n"
     ]
    }
   ],
   "source": [
    "print(dataMatrix.shape,vocabSize,\"\\n\",char_to_int,\"\\n\",int_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb6f07",
   "metadata": {},
   "source": [
    "#### Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2293f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training input-output pairs\n",
    "X_train = dataMatrix[:-1]  # All rows except the last one\n",
    "Y_train = dataMatrix[1:]   # All rows except the first one\n",
    "\n",
    "inputs = torch.Tensor(X_train)\n",
    "#Take the max number (1 in our case) indice of the one hot enocding alongside column\n",
    "labels = torch.Tensor(np.argmax(Y_train, axis=1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf8cd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "tensor([0., 0., 1., 0., 0., 0., 0.])\n",
      "{0: '\\n', 1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(int_to_char[2])\n",
    "print(inputs[0])\n",
    "print(int_to_char)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "923dd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGeneratorMLP(nn.Module):\n",
    "    def __init__(self,inputSize,outputSize):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.InputLayer = nn.Linear(in_features=inputSize,out_features=128)\n",
    "        self.HiddenLayer = nn.Linear(in_features=128,out_features=256)\n",
    "        self.HiddenLayer2 = nn.Linear(in_features=256,out_features=64)\n",
    "        self.OutputLayer = nn.Linear(in_features=64,out_features=outputSize)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.InputLayer(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.HiddenLayer(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.HiddenLayer2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.OutputLayer(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e53b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = TextGeneratorMLP(vocabSize,vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a404088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "416eb20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/200], Loss: 0.2218\n",
      "Epoch [100/200], Loss: 0.1097\n",
      "Epoch [150/200], Loss: 0.1078\n",
      "Epoch [200/200], Loss: 0.1070\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    # here no need to use outputs.argmax as criterion CrossEntropyLoss do this and softmax on our behalf\n",
    "    loss = criterion(outputs, labels.long()) \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b5e5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationFunction():\n",
    "    model.eval()\n",
    "    generatedString = \"\"\n",
    "    radomStartingPoint = np.random.randint(low=0,high=inputs.shape[0])\n",
    "    modelInput = inputs[radomStartingPoint]\n",
    "    startingInteger = torch.argmax(modelInput, dim=0).item()\n",
    "    startingCharacter = int_to_char[startingInteger]\n",
    "    #print(radomStartingPoint,modelInput)\n",
    "    for i in range(50):\n",
    "        output = model(modelInput)\n",
    "        predicted_index = torch.argmax(output, dim=0).item()\n",
    "        char = int_to_char[predicted_index]\n",
    "        generatedString += char\n",
    "        modelInput = torch.Tensor(np.eye(vocabSize)[char_to_int[char]])\n",
    "    \n",
    "    print(f\"Starting Character Randomly choosen in Integer: {startingInteger} in Alphabet: {startingCharacter}\")\n",
    "    print(\"Generated String:\", generatedString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ae20025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Character Randomly choosen in Integer: 3 in Alphabet: b\n",
      "Generated String: cde abcde abcde abcde abcde abcde abcde abcde abcd\n"
     ]
    }
   ],
   "source": [
    "evaluationFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42cad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02960e6c",
   "metadata": {},
   "source": [
    "### Text Generation with Input as Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "132904c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix , vocabSize, char_to_int,int_to_char = fileHandler(\"C:/Users/Lenovo/Desktop/My Git Repo/abcde_edcba.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c56e20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training input-output pairs\n",
    "X_train = np.concatenate((dataMatrix[:-2], dataMatrix[1:-1]), axis=1)  # Concatenate two consecutive one-hot-encoded vectors along columns\n",
    "Y_train = dataMatrix[2:]  # Next three one-hot-encoded vectors as output\n",
    "\n",
    "inputs = torch.Tensor(X_train)\n",
    "#Take the max number (1 in our case) indice of the one hot enocding alongside column\n",
    "labels = torch.Tensor(np.argmax(Y_train, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "75853944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0.] [0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(dataMatrix[0],dataMatrix[1],dataMatrix[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d9310dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] [0. 0. 0. 0. 1. 0. 0.] 4.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0],Y_train[0],labels[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe65560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = TextGeneratorMLP(vocabSize*2,vocabSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a0e7176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextGeneratorMLP(\n",
      "  (InputLayer): Linear(in_features=14, out_features=128, bias=True)\n",
      "  (HiddenLayer): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (HiddenLayer2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (OutputLayer): Linear(in_features=64, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fc77d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5978cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/150], Loss: 0.0860\n",
      "Epoch [100/150], Loss: 0.0025\n",
      "Epoch [150/150], Loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    # here no need to use outputs.argmax as criterion CrossEntropyLoss do this and softmax on our behalf\n",
    "    loss = criterion(outputs, labels.long()) \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a27359bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationFunction():\n",
    "    model.eval()\n",
    "    generatedString = \"\"\n",
    "    radomStartingPoint = np.random.randint(low=0,high=inputs.shape[0])\n",
    "    modelInput = inputs[radomStartingPoint]\n",
    "    startingInteger1 = torch.argmax(modelInput[:7], dim=0).item()\n",
    "    startingInteger2 = torch.argmax(modelInput[7:], dim=0).item()\n",
    "    startingCharacter1 = int_to_char[startingInteger1]\n",
    "    startingCharacter2 = int_to_char[startingInteger2]\n",
    "    #print(radomStartingPoint,modelInput)\n",
    "    for i in range(50):\n",
    "        #print(modelInput)\n",
    "        output = model(modelInput)\n",
    "        predicted_index = torch.argmax(output, dim=0).item()\n",
    "        char = int_to_char[predicted_index]\n",
    "        generatedString += char\n",
    "        newCharacterEncoding = torch.Tensor(np.eye(vocabSize)[char_to_int[char]])\n",
    "        modelInput = torch.cat((modelInput[-7:],newCharacterEncoding),dim=0)\n",
    "\n",
    "    print(f\"Starting Characters Randomly choosen in Alphabets: {startingCharacter1,startingCharacter2}\")\n",
    "    print(\"Generated String:\", generatedString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96b1adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Characters Randomly choosen in Alphabets: ('d', 'e')\n",
      "Generated String:  edcba\n",
      "abcde edcba\n",
      "abcde edcba\n",
      "abcde edcba\n",
      "abcde e\n"
     ]
    }
   ],
   "source": [
    "evaluationFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee63bbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153598"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380c572",
   "metadata": {},
   "source": [
    "### Text Generation with MLP Hidden State Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57f896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd77bbe6",
   "metadata": {},
   "source": [
    "#### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080b36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMatrix , vocabSize, char_to_int,int_to_char = fileHandler(\"C:/Users/Lenovo/Desktop/My Git Repo/abcde.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdce7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training input-output pairs\n",
    "X_train = dataMatrix[:-1]  # All rows except the last one\n",
    "Y_train = dataMatrix[1:]   # All rows except the first one\n",
    "\n",
    "inputs = torch.Tensor(X_train)\n",
    "#Take the max number (1 in our case) indice of the one hot enocding alongside column\n",
    "labels = torch.Tensor(np.argmax(Y_train, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e61b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7df3735",
   "metadata": {},
   "source": [
    "#### Implementing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5f89c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGeneratorHiddenStateMLP(nn.Module):\n",
    "    def __init__(self,inputSize,outputSize,hiddenStateSize):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hiddenStateSize = hiddenStateSize\n",
    "        self.InputLayer = nn.Linear(in_features=inputSize+hiddenStateSize,out_features=128)\n",
    "        self.HiddenLayer = nn.Linear(in_features=128,out_features=hiddenStateSize)\n",
    "        self.OutputLayer = nn.Linear(in_features=hiddenStateSize,out_features=outputSize)\n",
    "    \n",
    "    def forward(self,X,hiddenState=None):\n",
    "        if hiddenState is None:\n",
    "            hiddenState = torch.zeros(self.hiddenStateSize,requires_grad=False) # 1 row and hiddenStateSize columns\n",
    "        \n",
    "        outputs = []\n",
    "        for xPoints in X:\n",
    "            prevHiddenState = hiddenState\n",
    "            networkInput = torch.concat((xPoints,prevHiddenState),dim=0)\n",
    "            hiddenState = F.relu(self.HiddenLayer(F.relu(self.InputLayer(networkInput))))\n",
    "            yt = self.OutputLayer(hiddenState)\n",
    "            outputs.append(yt)\n",
    "        \n",
    "        return torch.stack(outputs), hiddenState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b777b4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextGeneratorHiddenStateMLP(\n",
       "  (InputLayer): Linear(in_features=17, out_features=128, bias=True)\n",
       "  (HiddenLayer): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (OutputLayer): Linear(in_features=10, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddenStateSize=10\n",
    "model = TextGeneratorHiddenStateMLP(vocabSize,vocabSize,hiddenStateSize)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "afe5171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember you can change parameters while training by interuppting the kernel and running it again, it will start from where it stopped.  \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12fd8e",
   "metadata": {},
   "source": [
    "#### Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d9cdb5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.3567\n",
      "Starting Character Randomly choosen in Integer: 0 in Alphabet: \n",
      "\n",
      "Generated String: ababababababababababababababababababababababababab\n",
      "Starting Character Randomly choosen in Integer: [5, 6, 1, 2] in Alphabet: ['d', 'e', ' ', 'a']\n",
      "Generated Character: b\n",
      "Epoch [2/20], Loss: 13.5137, Now breaking loop\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "prevLoss = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs,_ = model(inputs) #As in training we don't need hidden state \n",
    "    \n",
    "\n",
    "    # here no need to use outputs.argmax as criterion CrossEntropyLoss do this and softmax on our behalf\n",
    "    loss = criterion(outputs, labels.long())\n",
    "    if loss.item() > prevLoss:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Now breaking loop')\n",
    "        break\n",
    "    else:\n",
    "        prevLoss = loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    '''Remember you can change evaluation functions and this loop logic while training by interuppting the kernel \n",
    "    and running it again, it will start from where it stopped.  '''\n",
    "    if ((epoch+1) % 2 == 0 ) or epoch==0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        evaluationFunction1()\n",
    "        evaluationFunction2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6f107650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationFunction1():\n",
    "    model.eval()\n",
    "    generatedString = \"\"\n",
    "    radomStartingPoint = np.random.randint(low=0,high=inputs.shape[0])\n",
    "    modelInput = inputs[radomStartingPoint]\n",
    "    startingInteger = torch.argmax(modelInput, dim=0).item()\n",
    "    startingCharacter = int_to_char[startingInteger]\n",
    "    #print(radomStartingPoint,modelInput)\n",
    "    prevHiddenState=None\n",
    "    for i in range(50):\n",
    "        output,prevHiddenState = model(modelInput.reshape(1,-1),prevHiddenState)\n",
    "        predicted_index = torch.argmax(output, dim=1).item()\n",
    "        char = int_to_char[predicted_index]\n",
    "        generatedString += char\n",
    "        modelInput = torch.Tensor(np.eye(vocabSize)[char_to_int[char]])\n",
    "    \n",
    "    print(f\"Starting Character Randomly choosen in Integer: {startingInteger} in Alphabet: {startingCharacter}\")\n",
    "    print(\"Generated String:\", generatedString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "07f3d165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Character Randomly choosen in Integer: 4 in Alphabet: c\n",
      "Generated String: de abcde abcde abcde abcde abcde abcde abcde abcde\n"
     ]
    }
   ],
   "source": [
    "evaluationFunction1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5d173af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationFunction2():\n",
    "    model.eval()\n",
    "    startingInteger = []\n",
    "    startingCharacter = []\n",
    "    radomStartingPoint = np.random.randint(low=0,high=inputs.shape[0]-10)\n",
    "    \n",
    "    #let's give model a sequence to see what it generates next as a character \n",
    "    modelInput = inputs[radomStartingPoint:radomStartingPoint+4,:]    \n",
    "    for characterHotEncode in modelInput:\n",
    "        integer = torch.argmax(characterHotEncode, dim=0).item()\n",
    "        startingInteger.append(integer)\n",
    "        startingCharacter.append(int_to_char[integer])\n",
    "\n",
    "    output,prevHiddenState = model(modelInput)\n",
    "    lastOutput = output[-1] #As our concern is with last output which will tell what comes after running through sequence\n",
    "    predicted_index = torch.argmax(lastOutput, dim=0).item()\n",
    "    char = int_to_char[predicted_index]\n",
    "    \n",
    "    print(f\"Starting Character Randomly choosen in Integer: {startingInteger} in Alphabet: {startingCharacter}\")\n",
    "    print(\"Generated Character:\", char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e27e884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Character Randomly choosen in Integer: [6, 1, 2, 3] in Alphabet: ['e', ' ', 'a', 'b']\n",
      "Generated Character: c\n"
     ]
    }
   ],
   "source": [
    "evaluationFunction2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321deda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
